# Hadoop
- A Distributed Programming Framework

# Big data 
- is an extremely huge of data.Huge for big data means hundred/thousands of terabytes factors of big data
- volume tells you how big the data is growing
- Velocity (rate/ speed) tells you how fast your data is growing
- Variety refers to the all structure and unstructured data that is being generated
# Why do we need Hadoop?
-	Supports huge volume of data
-	Store efficiency
-	Good data recovery solution
-	Horizontal scaling
-	Cost effective 
-	Easy to use for programmers and non-programmers
Traditional solutions come with scalability problems
Databases cannot be scaled horizontally 

File system is an integral part of every operating system
FS controls how the data is stored and retrieved, has metadata about files and folders and manages stored space efficiently
# HDFS (Hadoop Distributed File System)    Why is it needed?
-	Supports distributed processing where files are stored in blocks
-	Replaces blocks â€“ prevent data loss or failures
-	scalability
